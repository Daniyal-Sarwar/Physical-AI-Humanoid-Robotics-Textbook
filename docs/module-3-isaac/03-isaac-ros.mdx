---
sidebar_position: 3
title: Isaac ROS
description: GPU-accelerated ROS 2 packages for perception and navigation
---

# Isaac ROS

## Learning Objectives

By the end of this chapter, you will be able to:

- Install Isaac ROS packages on NVIDIA Jetson and x86 platforms
- Deploy GPU-accelerated perception pipelines
- Use Isaac ROS for visual SLAM and navigation
- Integrate DNN inference with ROS 2 nodes
- Optimize performance for real-time robotics

## Prerequisites

- Completed previous Isaac chapters
- ROS 2 Humble installed
- NVIDIA GPU with CUDA support
- Docker experience (Isaac ROS uses containers)

---

## What is Isaac ROS?

**Isaac ROS** is NVIDIA's collection of GPU-accelerated ROS 2 packages:

- **Hardware acceleration**: CUDA, TensorRT, VPI
- **Production-ready**: Tested for reliability
- **Jetson optimized**: Runs on Jetson Orin, AGX, Nano
- **Standards-compliant**: Drop-in replacements for CPU packages

### Package Categories

| Category | Packages |
|----------|----------|
| **Perception** | AprilTag, object detection, segmentation |
| **SLAM** | Visual SLAM, stereo odometry |
| **Navigation** | Freespace segmentation, depth processing |
| **DNN** | TensorRT inference, ONNX support |
| **Sensors** | Argus camera, depth processing |

---

## Installation

### Using Docker (Recommended)

```bash title="Terminal"
# Clone Isaac ROS Common
git clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git
cd isaac_ros_common

# Build development container
./scripts/run_dev.sh

# Inside container: build Isaac ROS packages
cd /workspaces/isaac_ros-dev
colcon build --symlink-install
source install/setup.bash
```

### Native Installation

```bash title="Terminal"
# Add Isaac ROS apt repository
wget -qO - https://isaac.download.nvidia.com/isaac-ros/repos.key | \
    sudo apt-key add -
echo "deb https://isaac.download.nvidia.com/isaac-ros/ubuntu/main $(lsb_release -cs) main" | \
    sudo tee /etc/apt/sources.list.d/isaac-ros.list

# Install packages
sudo apt update
sudo apt install ros-humble-isaac-ros-visual-slam
sudo apt install ros-humble-isaac-ros-apriltag
```

---

## Visual SLAM

### cuVSLAM: GPU-Accelerated SLAM

```python title="launch/visual_slam.launch.py"
from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='isaac_ros_visual_slam',
            executable='visual_slam_node',
            name='visual_slam',
            parameters=[{
                'enable_localization_n_mapping': True,
                'enable_imu_fusion': True,
                'gyro_noise_density': 0.00016,
                'gyro_random_walk': 0.000022,
                'accel_noise_density': 0.00071,
                'accel_random_walk': 0.00026,
            }],
            remappings=[
                ('visual_slam/image_0', '/camera/left/image_raw'),
                ('visual_slam/camera_info_0', '/camera/left/camera_info'),
                ('visual_slam/image_1', '/camera/right/image_raw'),
                ('visual_slam/camera_info_1', '/camera/right/camera_info'),
            ]
        )
    ])
```

### Performance Comparison

| SLAM Method | Platform | FPS | CPU Usage |
|-------------|----------|-----|-----------|
| ORB-SLAM3 (CPU) | Jetson Orin | 15 | 100% |
| cuVSLAM (GPU) | Jetson Orin | 60 | 20% |
| cuVSLAM (GPU) | RTX 3080 | 120 | 5% |

---

## Object Detection

### Isaac ROS DNN Inference

```python title="launch/detection.launch.py"
from launch import LaunchDescription
from launch_ros.actions import ComposableNodeContainer
from launch_ros.descriptions import ComposableNode

def generate_launch_description():
    return LaunchDescription([
        ComposableNodeContainer(
            name='detection_container',
            namespace='',
            package='rclcpp_components',
            executable='component_container_mt',
            composable_node_descriptions=[
                # Encoder: Resize and normalize
                ComposableNode(
                    package='isaac_ros_dnn_image_encoder',
                    plugin='nvidia::isaac_ros::dnn_inference::DnnImageEncoderNode',
                    name='dnn_image_encoder',
                    parameters=[{
                        'input_image_width': 1920,
                        'input_image_height': 1080,
                        'network_image_width': 640,
                        'network_image_height': 480,
                    }],
                    remappings=[
                        ('image', '/camera/image_raw'),
                    ]
                ),
                # TensorRT inference
                ComposableNode(
                    package='isaac_ros_tensor_rt',
                    plugin='nvidia::isaac_ros::dnn_inference::TensorRTNode',
                    name='tensor_rt',
                    parameters=[{
                        'model_file_path': '/models/yolov8n.onnx',
                        'engine_file_path': '/models/yolov8n.engine',
                        'input_tensor_names': ['images'],
                        'output_tensor_names': ['output0'],
                    }]
                ),
                # Decoder: Process detections
                ComposableNode(
                    package='isaac_ros_yolov8',
                    plugin='nvidia::isaac_ros::yolov8::YoloV8DecoderNode',
                    name='yolov8_decoder',
                    parameters=[{
                        'confidence_threshold': 0.5,
                        'nms_threshold': 0.45,
                    }]
                ),
            ],
        )
    ])
```

---

## AprilTag Detection

```python title="AprilTag Node"
from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='isaac_ros_apriltag',
            executable='isaac_ros_apriltag',
            name='apriltag',
            parameters=[{
                'size': 0.1,  # Tag size in meters
                'max_tags': 20,
            }],
            remappings=[
                ('image', '/camera/image_raw'),
                ('camera_info', '/camera/camera_info'),
            ]
        )
    ])
```

### Performance

| Method | Platform | Tags | FPS |
|--------|----------|------|-----|
| CPU AprilTag | Jetson Orin | 10 | 8 |
| Isaac ROS | Jetson Orin | 10 | 60 |
| Isaac ROS | RTX 3080 | 20 | 200 |

---

## Navigation Stack

### Freespace Segmentation

```python title="Freespace for Navigation"
Node(
    package='isaac_ros_bi3d_freespace',
    executable='isaac_ros_bi3d_freespace',
    name='freespace_segmentation',
    parameters=[{
        'base_link_frame': 'base_link',
        'camera_frame': 'camera_link',
        'f_x': 380.0,
        'f_y': 380.0,
        'grid_width': 100,
        'grid_height': 100,
        'grid_resolution': 0.05,
    }]
)
```

---

## Summary

In this chapter, you learned:

- ✅ Isaac ROS provides GPU-accelerated ROS 2 packages
- ✅ cuVSLAM offers real-time visual SLAM on Jetson
- ✅ TensorRT integration enables fast DNN inference
- ✅ AprilTag detection achieves 10x speedup on GPU
- ✅ Docker containers simplify deployment

---

## Exercises

### Exercise 1: Camera Pipeline (Basic)

Deploy Isaac ROS with:
1. USB camera driver
2. Image rectification
3. AprilTag detection
4. Visualize in RViz

### Exercise 2: Custom Detection (Intermediate)

Train and deploy:
1. Custom YOLO model for your objects
2. Export to ONNX format
3. Deploy with Isaac ROS TensorRT
4. Measure latency and accuracy

### Exercise 3: Mobile Robot Navigation (Advanced)

Build a navigation system with:
1. Stereo camera visual SLAM
2. Freespace segmentation
3. Nav2 integration
4. Autonomous waypoint following

---

## References

1. [Isaac ROS Documentation](https://nvidia-isaac-ros.github.io/)
2. [Isaac ROS GitHub](https://github.com/NVIDIA-ISAAC-ROS)
3. [NVIDIA Jetson Developer](https://developer.nvidia.com/embedded-computing)
